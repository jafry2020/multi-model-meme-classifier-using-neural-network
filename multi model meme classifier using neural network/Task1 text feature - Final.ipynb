{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cec49fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9ab38fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_data =  pd.read_csv(\"sentiment.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cad93a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "del excel_data['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95d5e281",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_data.drop(excel_data[excel_data.filename == 'COCO_val2014_000000130712.jpg'].index , inplace=True)\n",
    "excel_data.drop(excel_data[excel_data.filename == 'COCO_val2014_000000310622.jpg'].index , inplace=True)\n",
    "excel_data.drop(excel_data[excel_data.filename == 'COCO_val2014_000000421673.jpg'].index , inplace=True)\n",
    "excel_data.drop(excel_data[excel_data.filename == 'COCO_val2014_000000359276.jpg'].index , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d828b8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import string \n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fed4587",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = excel_data[\"raw\"].astype(\"str\").tolist()\n",
    "final=[]\n",
    "final2=[]\n",
    "for i in text:\n",
    "    name_tokens = nltk.word_tokenize(i.lower())\n",
    "    test=[]\n",
    "    for i in name_tokens:\n",
    "        if (i in string.punctuation or i in stopwords.words('english')):\n",
    "            x=-1\n",
    "        else:\n",
    "            test.append(i)\n",
    "\n",
    "    final=test\n",
    "    final2.append(\" \".join(final))\n",
    "    \n",
    "    \"\"\"note: remove the word_sentiment from list of \n",
    "    words that are not included in the updated cleaned words\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a73f68fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              plate delicious food including french fries\n",
       "1        french fries healthy food excellent food teena...\n",
       "2                    plate one favorite foods french fries\n",
       "3                                 disgusting food bad food\n",
       "4                        plate disgusting food found diner\n",
       "                               ...                        \n",
       "39194           dirty bathroom dirty window made dead wood\n",
       "39195                                dirty bathroom window\n",
       "39196                            towel rack dirty bathroom\n",
       "39197           dirty bathroom dirty window made dead wood\n",
       "39198                                dirty bathroom window\n",
       "Name: raw, Length: 39109, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "excel_data[\"raw\"] = final2\n",
    "tokens  = excel_data[\"tokens\"]\n",
    "excel_data[\"raw\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a56890",
   "metadata": {},
   "source": [
    "# text to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0805b208",
   "metadata": {},
   "outputs": [],
   "source": [
    "text= np.array(excel_data[\"raw\"])\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=4096)\n",
    "vectorizer.fit(text.astype('U'))\n",
    "testing=vectorizer.transform(text.astype('U'))\n",
    "matrix=testing.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b83b86e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>18</th>\n",
       "      <th>20th</th>\n",
       "      <th>300</th>\n",
       "      <th>40</th>\n",
       "      <th>555</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>able</th>\n",
       "      <th>aboard</th>\n",
       "      <th>abroad</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>...</th>\n",
       "      <th>yummy</th>\n",
       "      <th>zebra</th>\n",
       "      <th>zebras</th>\n",
       "      <th>zero</th>\n",
       "      <th>zips</th>\n",
       "      <th>zone</th>\n",
       "      <th>zones</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zookeeper</th>\n",
       "      <th>zookeepers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 4096 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    18  20th  300   40  555  abandoned  able  aboard  abroad  absolutely  ...  \\\n",
       "0  0.0   0.0  0.0  0.0  0.0        0.0   0.0     0.0     0.0         0.0  ...   \n",
       "1  0.0   0.0  0.0  0.0  0.0        0.0   0.0     0.0     0.0         0.0  ...   \n",
       "2  0.0   0.0  0.0  0.0  0.0        0.0   0.0     0.0     0.0         0.0  ...   \n",
       "3  0.0   0.0  0.0  0.0  0.0        0.0   0.0     0.0     0.0         0.0  ...   \n",
       "4  0.0   0.0  0.0  0.0  0.0        0.0   0.0     0.0     0.0         0.0  ...   \n",
       "\n",
       "   yummy  zebra  zebras  zero  zips  zone  zones  zoo  zookeeper  zookeepers  \n",
       "0    0.0    0.0     0.0   0.0   0.0   0.0    0.0  0.0        0.0         0.0  \n",
       "1    0.0    0.0     0.0   0.0   0.0   0.0    0.0  0.0        0.0         0.0  \n",
       "2    0.0    0.0     0.0   0.0   0.0   0.0    0.0  0.0        0.0         0.0  \n",
       "3    0.0    0.0     0.0   0.0   0.0   0.0    0.0  0.0        0.0         0.0  \n",
       "4    0.0    0.0     0.0   0.0   0.0   0.0    0.0  0.0        0.0         0.0  \n",
       "\n",
       "[5 rows x 4096 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.DataFrame(testing.toarray(), columns= vectorizer.get_feature_names())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da2724fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# with open('text.pkl', 'wb') as f:\n",
    "#     pickle.dump(matrix, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6d739d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('text.pkl', 'rb') as f:\n",
    "    matrix = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c91f080c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def convert_to_tensor(file):\n",
    "    tensor = torch.tensor(file, dtype=torch.float32)\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "da51f678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4096}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_tensor = convert_to_tensor(matrix)\n",
    "\n",
    "#to check if all tensors have same lenght\n",
    "leng = []\n",
    "for i in text_tensor:\n",
    "    leng.append(len(i))\n",
    "    \n",
    "set(leng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "121a24f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6647e0e5",
   "metadata": {},
   "source": [
    "hence proved every tensor has the same lenght\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "29938c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('text_tensors.pkl', 'wb') as f:\n",
    "    pickle.dump(text_tensor, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
