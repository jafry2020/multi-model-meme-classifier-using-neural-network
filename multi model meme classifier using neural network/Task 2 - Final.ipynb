{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d3f8353",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "\n",
    "import nltk\n",
    "import string \n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import ast\n",
    "from bert_serving.client import BertClient\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1198d335",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_data =  pd.read_csv(\"sentiment.csv\")\n",
    "del excel_data['Unnamed: 0']\n",
    "\n",
    "excel_data.drop(excel_data[excel_data.filename == 'COCO_val2014_000000130712.jpg'].index , inplace=True)\n",
    "excel_data.drop(excel_data[excel_data.filename == 'COCO_val2014_000000310622.jpg'].index , inplace=True)\n",
    "excel_data.drop(excel_data[excel_data.filename == 'COCO_val2014_000000421673.jpg'].index , inplace=True)\n",
    "excel_data.drop(excel_data[excel_data.filename == 'COCO_val2014_000000359276.jpg'].index , inplace=True)\n",
    "\n",
    "data = excel_data[['imgid', 'filename', 'successful', 'tokens', 'word_sentiment', 'sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "336f9dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens =  data['tokens']\n",
    "sen = data['word_sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c79325",
   "metadata": {},
   "source": [
    "# converting String tokens to actual list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09eba548",
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_tokens = []\n",
    "for token in tokens:\n",
    "    string = token\n",
    "    sets = ast.literal_eval(string)\n",
    "    converted_tokens.append(sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b121fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_sentiments = []\n",
    "for sentiment in sen:\n",
    "    new_sen = [float(x.strip()) for x in sentiment.strip('[]').split(',')]\n",
    "    converted_sentiments.append(new_sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44b33c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1888\\3501353506.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['tokens'] = converted_tokens\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1888\\3501353506.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['word_sentiment'] = converted_sentiments\n"
     ]
    }
   ],
   "source": [
    "data['tokens'] = converted_tokens\n",
    "data['word_sentiment'] = converted_sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe9f007",
   "metadata": {},
   "source": [
    "we are going to send final sentiments to tell these strings havve overall positive/negitive sentiment and now the modedl will have to find which words are cotribuiting to that sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e6c2de",
   "metadata": {},
   "source": [
    "# convertinng to 5 grams "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad09a07c",
   "metadata": {},
   "source": [
    "includes the middle token, 2 before and after middle token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "069a8a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(token, sentiment):\n",
    "    if (len(token)%2 == 1):\n",
    "        middle_index = len(token) // 2\n",
    "    else:\n",
    "        middle_index = (len(token) // 2 )- 1\n",
    "\n",
    "    gram = token[middle_index-2:middle_index+3]\n",
    "    sentiment = sentiment[middle_index-2:middle_index+3]\n",
    "    \n",
    "    return (gram, sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c29cbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "datacopy = copy.deepcopy(data)\n",
    "data = datacopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28d00899",
   "metadata": {},
   "outputs": [],
   "source": [
    "gram5_tokens = []\n",
    "gram5_sentiments = []\n",
    "target_token = []\n",
    "target_sentiment = []\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    tokens = row[3]; sent = row[4]\n",
    "    \n",
    "    gram5 = convert(tokens, sent)\n",
    "    \n",
    "    gram5_tokens.append(gram5[0])\n",
    "    gram5_sentiments.append(gram5[1])\n",
    "    \n",
    "    target_token.append(gram5[0][2])\n",
    "    target_sentiment.append(gram5[1][2])\n",
    "\n",
    "data['tokens'] = gram5_tokens\n",
    "data['word_sentiment'] = gram5_sentiments\n",
    "data['target_token'] = target_token\n",
    "data['target_sentiment'] = target_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78957055",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[[\"tokens\" , \"word_sentiment\" , 'target_token', 'target_sentiment', \"sentiment\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43fa1753",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1888\\1873234889.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['text'] = data['tokens'].apply(lambda x: ' '.join(x))\n"
     ]
    }
   ],
   "source": [
    "data['text'] = data['tokens'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff71957",
   "metadata": {},
   "source": [
    "# Feature Eextraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c5c7ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text= np.array(data[\"text\"])\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3b6cd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(text.astype('U'))\n",
    "testing=vectorizer.transform(text.astype('U'))\n",
    "matrix=testing.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7311bb4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>555</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>able</th>\n",
       "      <th>aboard</th>\n",
       "      <th>about</th>\n",
       "      <th>above</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>abstract</th>\n",
       "      <th>abused</th>\n",
       "      <th>accented</th>\n",
       "      <th>...</th>\n",
       "      <th>you</th>\n",
       "      <th>young</th>\n",
       "      <th>your</th>\n",
       "      <th>zebra</th>\n",
       "      <th>zebras</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zookeeper</th>\n",
       "      <th>zooming</th>\n",
       "      <th>zooms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   555  abandoned  able  aboard  about  above  absolutely  abstract  abused  \\\n",
       "0  0.0        0.0   0.0     0.0    0.0    0.0         0.0       0.0     0.0   \n",
       "1  0.0        0.0   0.0     0.0    0.0    0.0         0.0       0.0     0.0   \n",
       "2  0.0        0.0   0.0     0.0    0.0    0.0         0.0       0.0     0.0   \n",
       "3  0.0        0.0   0.0     0.0    0.0    0.0         0.0       0.0     0.0   \n",
       "4  0.0        0.0   0.0     0.0    0.0    0.0         0.0       0.0     0.0   \n",
       "\n",
       "   accented  ...  you  young  your  zebra  zebras  zone  zoo  zookeeper  \\\n",
       "0       0.0  ...  0.0    0.0   0.0    0.0     0.0   0.0  0.0        0.0   \n",
       "1       0.0  ...  0.0    0.0   0.0    0.0     0.0   0.0  0.0        0.0   \n",
       "2       0.0  ...  0.0    0.0   0.0    0.0     0.0   0.0  0.0        0.0   \n",
       "3       0.0  ...  0.0    0.0   0.0    0.0     0.0   0.0  0.0        0.0   \n",
       "4       0.0  ...  0.0    0.0   0.0    0.0     0.0   0.0  0.0        0.0   \n",
       "\n",
       "   zooming  zooms  \n",
       "0      0.0    0.0  \n",
       "1      0.0    0.0  \n",
       "2      0.0    0.0  \n",
       "3      0.0    0.0  \n",
       "4      0.0    0.0  \n",
       "\n",
       "[5 rows x 3105 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.DataFrame(testing.toarray(), columns= vectorizer.get_feature_names())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9f116f",
   "metadata": {},
   "source": [
    "features to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a8f2296",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def convert_to_tensor(file):\n",
    "    tensor = torch.tensor(file, dtype=torch.float32)\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca173449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3105}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_tensor = convert_to_tensor(matrix)\n",
    "\n",
    "#to check if all tensors have same lenght\n",
    "leng = []\n",
    "for i in text_tensor:\n",
    "    leng.append(len(i))\n",
    "    \n",
    "set(leng)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a59d91",
   "metadata": {},
   "source": [
    "dump features using pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c6b70d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Write the dictionary to a file using pickle.dump\n",
    "with open('task2.pkl', 'wb') as f:\n",
    "    pickle.dump(text_tensor, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb7bd7f",
   "metadata": {},
   "source": [
    "# define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "00a15765",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel_Multi(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(in_features=3105, out_features=2500)\n",
    "        self.l2 = nn.Linear(in_features=2500, out_features=2000)\n",
    "        self.l3 = nn.Linear(in_features=2000, out_features=1000)\n",
    "        self.l4 = nn.Linear(in_features=4096, out_features=2500)\n",
    "        self.l5 = nn.Linear(in_features=2500, out_features=2000)\n",
    "        self.l6 = nn.Linear(in_features=2000, out_features=1000)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x1):\n",
    "        x1 = self.l1(x1)\n",
    "        x1 = self.sigmoid(x1)\n",
    "        x1 = self.l2(x1)\n",
    "        x1 = self.sigmoid(x1)\n",
    "        x1 = self.l3(x1)\n",
    "        x1 = self.sigmoid(x1)\n",
    "        x1 = self.l4(x1)\n",
    "        x1 = self.sigmoid(x1)\n",
    "        x1 = self.l5(x1)\n",
    "        x1 = self.sigmoid(x1)\n",
    "        x1 = self.l6(x1)\n",
    "        x1 = self.sigmoid(x1)\n",
    "\n",
    "        return x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a4c26b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class sentiment(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(in_features=3105, out_features=2500)\n",
    "        self.bn1 = nn.BatchNorm1d(num_features=2500)\n",
    "        self.l2 = nn.Linear(in_features=2500, out_features=2000)\n",
    "        self.bn2 = nn.BatchNorm1d(num_features=2000)\n",
    "        self.l3 = nn.Linear(in_features=2000, out_features=1000)\n",
    "        self.bn3 = nn.BatchNorm1d(num_features=1000)\n",
    "        self.l4 = nn.Linear(in_features=1000, out_features=500)\n",
    "        self.bn4 = nn.BatchNorm1d(num_features=500)\n",
    "        self.l5 = nn.Linear(in_features=500, out_features=250)\n",
    "        self.bn5 = nn.BatchNorm1d(num_features=250)\n",
    "        self.l6 = nn.Linear(in_features=250, out_features=100)\n",
    "        self.bn6 = nn.BatchNorm1d(num_features=100)\n",
    "        self.l7 = nn.Linear(in_features=100, out_features=50)\n",
    "        self.bn7 = nn.BatchNorm1d(num_features=50)\n",
    "        self.l8 = nn.Linear(in_features=50, out_features=1)\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.l1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.l2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.l3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.l4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.l5(x)\n",
    "        x = self.bn5(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.l6(x)\n",
    "        x = self.bn6(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.l7(x)\n",
    "        x = self.bn7(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.l8(x)\n",
    "        x = self.sigmoid(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7219fd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class sentiment_sigmoid(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(in_features=3105, out_features=2500)\n",
    "        self.l2 = nn.Linear(in_features=2500, out_features=2000)\n",
    "        self.l3 = nn.Linear(in_features=2000, out_features=1000)\n",
    "        self.l4 = nn.Linear(in_features=1000, out_features=500)\n",
    "        self.l5 = nn.Linear(in_features=500, out_features=250)\n",
    "        self.l6 = nn.Linear(in_features=250, out_features=100)\n",
    "        self.l7 = nn.Linear(in_features=100, out_features=50)\n",
    "        self.l8 = nn.Linear(in_features=50, out_features=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.l1(x)\n",
    "        x = self.sigmoid(x)\n",
    "\n",
    "        x = self.l2(x)\n",
    "        x = self.sigmoid(x)\n",
    "\n",
    "        x = self.l3(x)\n",
    "        x = self.sigmoid(x)\n",
    "\n",
    "        x = self.l4(x)\n",
    "        x = self.sigmoid(x)\n",
    "\n",
    "        x = self.l5(x)\n",
    "        x = self.sigmoid(x)\n",
    "\n",
    "        x = self.l6(x)\n",
    "        x = self.sigmoid(x)\n",
    "\n",
    "        x = self.l7(x)\n",
    "        x = self.sigmoid(x)\n",
    "\n",
    "        x = self.l8(x)\n",
    "        x = self.sigmoid(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "16a2874f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sentiment_sigmoid()\n",
    "# model  = MyModel_Multi()\n",
    "loss = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47fd934",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7f0547",
   "metadata": {},
   "source": [
    "# Load features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "29f03da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('task2.pkl', 'rb') as f:\n",
    "    text = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87b1e2e",
   "metadata": {},
   "source": [
    "# target sentiment to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "14a54ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = data['target_sentiment'] # assuming 'sentiment' is a pandas series object\n",
    "sentiment_array = np.array([sentiment.to_numpy()]).T\n",
    "target = torch.tensor(sentiment_array, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "72a73a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('task2.pkl', 'rb') as f:\n",
    "    text_tensors = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5fbb6de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([39109, 3105]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "print(text_tensors.shape, text_tensors.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "47abf436",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(train_size = 0.8):\n",
    "    if train_size > 1:\n",
    "        print(\"sending default 0.8 train size\")\n",
    "        ret = split(0.8)\n",
    "        return ret\n",
    "    else:\n",
    "        rows = int(len(text_tensors)*train_size)\n",
    "        data = [ text_tensors[:rows, :], target[:rows, :], text_tensors[rows:, :], target[rows:, :] ]\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "979cf39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, ytrain, xtest, ytest= split(0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0066a1cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a70d5414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4577],\n",
       "        [0.4577],\n",
       "        [0.4577],\n",
       "        ...,\n",
       "        [0.4577],\n",
       "        [0.4577],\n",
       "        [0.4577]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b198fd",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7635037f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Loss: 0.9364\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "for epoch in range(1):\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs = model(xtrain)\n",
    "    loss = loss(outputs, ytrain)\n",
    "\n",
    "    # Backward pass\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Print progress\n",
    "    if (epoch+1) % 1 == 0:\n",
    "        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, 3, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0dfd90",
   "metadata": {},
   "source": [
    "# save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "55e5d387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume 'model' is your trained PyTorch model\n",
    "torch.save(model.state_dict(), 'task2_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4702946c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a new instance of your model\n",
    "model2 = sentiment_sigmoid()\n",
    "# load the saved parameters into the model\n",
    "model2.load_state_dict(torch.load('task2_model.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0675e108",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "365ff859",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "06bf4636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment_sigmoid(\n",
       "  (l1): Linear(in_features=3105, out_features=2500, bias=True)\n",
       "  (l2): Linear(in_features=2500, out_features=2000, bias=True)\n",
       "  (l3): Linear(in_features=2000, out_features=1000, bias=True)\n",
       "  (l4): Linear(in_features=1000, out_features=500, bias=True)\n",
       "  (l5): Linear(in_features=500, out_features=250, bias=True)\n",
       "  (l6): Linear(in_features=250, out_features=100, bias=True)\n",
       "  (l7): Linear(in_features=100, out_features=50, bias=True)\n",
       "  (l8): Linear(in_features=50, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
